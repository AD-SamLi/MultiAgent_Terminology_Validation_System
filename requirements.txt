# Agentic Terminology Validation System - Requirements
# Generated: September 30, 2025
# Python Version: 3.8+
# System Version: v1.0.0 (9-Step Pipeline with GPT-4.1 Context Generation)

# Core Dependencies
pandas>=2.0.0
numpy>=1.24.0
torch>=2.0.0
transformers>=4.30.0
nltk>=3.8.0
scikit-learn>=1.3.0

# Azure AI Services (Required for Step 9 Context Generation)
azure-ai-textanalytics>=5.3.0
azure-identity>=1.13.0
openai>=1.0.0
azure-cognitiveservices-language-textanalytics>=5.2.0

# Agentic Framework (Smolagents)
smolagents>=0.1.0
huggingface-hub>=0.16.0

# Translation and NLP (NLLB-200 Support)
sentencepiece>=0.1.99
sacremoses>=0.0.53
tokenizers>=0.13.0
protobuf>=3.20.0

# Data Processing and File Handling
openpyxl>=3.1.0
xlsxwriter>=3.1.0
chardet>=5.1.0
python-dateutil>=2.8.0
jsonlines>=3.1.0

# Multiprocessing and Performance Optimization
psutil>=5.9.0
tqdm>=4.65.0
joblib>=1.3.0
concurrent-futures>=3.1.1
multiprocess>=0.70.0

# File and Data Management
pathlib2>=2.3.7
glob2>=0.7
jsonschema>=4.17.0
pydantic>=2.0.0

# Logging and Monitoring
colorlog>=6.7.0
rich>=13.4.0
loguru>=0.7.0

# HTTP and API Clients
requests>=2.31.0
httpx>=0.24.0
aiohttp>=3.8.0

# GPU and CUDA Support (Optional but Recommended)
# Uncomment if using GPU acceleration for translation
# torch-audio>=2.0.0
# torchaudio>=2.0.0
# cuda-toolkit>=11.8  # Match your CUDA version
# GPUtil>=1.4.0  # For GPU monitoring

# Development and Testing (Optional)
# pytest>=7.4.0
# pytest-cov>=4.1.0
# pytest-asyncio>=0.21.0
# black>=23.7.0
# flake8>=6.0.0
# mypy>=1.5.0

# Additional Dependencies for Enhanced Features
regex>=2023.6.3
Pillow>=10.0.0
matplotlib>=3.7.0  # For visualization (optional)
seaborn>=0.12.0    # For advanced plotting (optional)

# System Requirements:
# ===================
# Minimum Configuration:
# - RAM: 16GB (32GB+ recommended for large datasets)
# - CPU: 8+ cores (16+ cores recommended)
# - Storage: 50GB+ free space
# - GPU: Optional but recommended (Tesla T4, RTX 3080+, or similar)
# - Network: Stable internet for Azure OpenAI API calls

# Optimal Configuration:
# - RAM: 64GB+
# - CPU: 32+ cores
# - Storage: 500GB+ NVMe SSD
# - GPU: Multi-GPU setup (up to 3 GPUs supported)
# - Network: 1 Gbps+ for faster model downloads

# Installation Instructions:
# =========================
# 1. Create virtual environment:
#    python -m venv venv
#
# 2. Activate virtual environment:
#    Linux/Mac: source venv/bin/activate
#    Windows: venv\Scripts\activate
#
# 3. Upgrade pip:
#    pip install --upgrade pip
#
# 4. Install requirements:
#    pip install -r requirements.txt
#
# 5. Download NLTK data:
#    python -c "import nltk; nltk.download('punkt'); nltk.download('wordnet'); nltk.download('omw-1.4')"
#
# 6. Verify installation:
#    python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"

# Azure Configuration (Required):
# ===============================
# Set the following environment variables:
#
# Required for Azure OpenAI (Step 9 Context Generation):
# export AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com/"
# export AZURE_CLIENT_ID="your-service-principal-client-id"
# export AZURE_CLIENT_SECRET="your-service-principal-secret"
# export AZURE_TENANT_ID="your-azure-tenant-id"
#
# Optional Performance Settings:
# export CUDA_VISIBLE_DEVICES="0,1,2"  # Multi-GPU support
# export OMP_NUM_THREADS="16"
# export TOKENIZERS_PARALLELISM="false"
# export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:512"

# Feature Support Matrix:
# ======================
# ✅ 9-Step Processing Pipeline
# ✅ Dynamic Resource Allocation (CPU/GPU)
# ✅ Multi-GPU Translation Support (up to 3 GPUs)
# ✅ Azure OpenAI GPT-4.1 Context Generation
# ✅ Smolagents Agentic Framework
# ✅ NLLB-200 Multi-Language Translation (200+ languages)
# ✅ Intelligent Gap Detection and Recovery
# ✅ Professional CSV Export with Contexts
# ✅ Comprehensive Quality Scoring
# ✅ Translatability Analysis
# ✅ Batch Processing with Checkpoints
# ✅ Enhanced Error Handling and Fallbacks

# Troubleshooting:
# ===============
# If you encounter issues:
# 1. Check Python version: python --version (3.8+ required)
# 2. Verify GPU setup: nvidia-smi (if using GPU)
# 3. Test Azure connectivity: az login && az account show
# 4. Check disk space: df -h (Linux/Mac) or dir (Windows)
# 5. Monitor memory usage during processing
#
# For support, check:
# - README.md for usage instructions
# - TECHNICAL_DOCUMENTATION.md for detailed technical information
# - System logs in agentic_terminology_validation.log