<?xml version="1.0" encoding="UTF-8"?>
<svg width="1400" height="1100" viewBox="0 0 1400 1100" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <style>
      .title { font: bold 26px Arial; fill: #2c3e50; text-anchor: middle; }
      .subtitle { font: bold 18px Arial; fill: #34495e; text-anchor: middle; }
      .section-title { font: bold 16px Arial; fill: #fff; text-anchor: middle; }
      .label { font: 13px Arial; fill: #2c3e50; text-anchor: middle; }
      .small-label { font: 11px Arial; fill: #fff; text-anchor: middle; }
      .tiny-label { font: 10px Arial; fill: #7f8c8d; text-anchor: middle; }
      .code-text { font: 10px Courier; fill: #2c3e50; }
      
      .gpu-box { fill: #e74c3c; stroke: #c0392b; stroke-width: 3; }
      .cpu-box { fill: #3498db; stroke: #2980b9; stroke-width: 3; }
      .innovation-box { fill: #f39c12; stroke: #e67e22; stroke-width: 3; }
      .success-box { fill: #2ecc71; stroke: #27ae60; stroke-width: 3; }
      .worker-box { fill: #9b59b6; stroke: #8e44ad; stroke-width: 2; }
      .code-box { fill: #ecf0f1; stroke: #bdc3c7; stroke-width: 2; }
      
      .arrow { stroke: #34495e; stroke-width: 2; fill: none; marker-end: url(#arrowhead); }
      .gpu-arrow { stroke: #e74c3c; stroke-width: 3; fill: none; marker-end: url(#gpu-arrowhead); }
      .cpu-arrow { stroke: #3498db; stroke-width: 3; fill: none; marker-end: url(#cpu-arrowhead); }
      .white-text { fill: white; }
    </style>
    
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#34495e" />
    </marker>
    <marker id="gpu-arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#e74c3c" />
    </marker>
    <marker id="cpu-arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#3498db" />
    </marker>
  </defs>

  <!-- Title -->
  <text x="700" y="35" class="title">Innovation 2: Adaptive Multi-GPU Resource Orchestration</text>
  <text x="700" y="60" class="subtitle">Dynamic Worker Allocation with Intelligent Load Distribution</text>

  <!-- System Detection Phase -->
  <text x="700" y="100" class="subtitle">Phase 1: System Detection & Analysis</text>

  <!-- Hardware Detection -->
  <rect x="50" y="130" width="400" height="130" class="innovation-box" rx="8"/>
  <text x="250" y="155" class="section-title white-text">GPU Detection & VRAM Analysis</text>
  <rect x="60" y="165" width="380" height="85" class="code-box" rx="4"/>
  <text x="70" y="180" class="code-text">if not torch.cuda.is_available():</text>
  <text x="70" y="193" class="code-text">    return 0  # Fall back to CPU</text>
  <text x="70" y="206" class="code-text">gpu_memory_gb = torch.cuda.get_device_properties(0)</text>
  <text x="70" y="219" class="code-text">                .total_memory / (1024**3)</text>
  <text x="70" y="232" class="code-text"># 16GB, 24GB, 32GB VRAM detected</text>
  <text x="70" y="245" class="code-text">available_gpus = torch.cuda.device_count()  # 1-3</text>

  <!-- CPU & Memory Detection -->
  <rect x="500" y="130" width="400" height="130" class="innovation-box" rx="8"/>
  <text x="700" y="155" class="section-title white-text">CPU & Memory Detection</text>
  <rect x="510" y="165" width="380" height="85" class="code-box" rx="4"/>
  <text x="520" y="180" class="code-text">cpu_cores = psutil.cpu_count()  # 8, 16, 32+</text>
  <text x="520" y="193" class="code-text">memory_gb = psutil.virtual_memory().total</text>
  <text x="520" y="206" class="code-text">            / (1024**3)  # 16GB, 32GB, 64GB+</text>
  <text x="520" y="219" class="code-text">os_name = platform.system()  # Windows/Linux</text>
  <text x="520" y="232" class="code-text"># Different optimization for each OS</text>
  <text x="520" y="245" class="code-text"># Windows: More conservative CPU allocation</text>

  <!-- OS-Specific Optimization -->
  <rect x="950" y="130" width="400" height="130" class="innovation-box" rx="8"/>
  <text x="1150" y="155" class="section-title white-text">OS-Specific Optimization</text>
  <rect x="960" y="165" width="380" height="85" class="code-box" rx="4"/>
  <text x="970" y="180" class="code-text">if os_name == "Windows":</text>
  <text x="970" y="193" class="code-text">    if memory_gb >= 32 and cpu_cores >= 16:</text>
  <text x="970" y="206" class="code-text">        optimal_workers = min(cpu_cores // 2, 12)</text>
  <text x="970" y="219" class="code-text">else:  # Linux/Mac - more efficient</text>
  <text x="970" y="232" class="code-text">    if memory_gb >= 16:</text>
  <text x="970" y="245" class="code-text">        optimal_workers = min(cpu_cores - 1, 16)</text>

  <!-- GPU Worker Calculation Phase -->
  <text x="700" y="310" class="subtitle">Phase 2: Dynamic GPU Worker Calculation</text>

  <!-- Model Memory Requirements -->
  <rect x="100" y="340" width="500" height="150" class="gpu-box" rx="8"/>
  <text x="350" y="365" class="section-title white-text">Model Memory Requirements</text>
  <rect x="110" y="375" width="480" height="105" class="code-box" rx="4"/>
  <text x="120" y="390" class="code-text"># Patent Claim: Model-specific VRAM calculation</text>
  <text x="120" y="403" class="code-text">model_memory_requirements = {</text>
  <text x="120" y="416" class="code-text">    "600M": 4.0,   # 4GB VRAM per worker</text>
  <text x="120" y="429" class="code-text">    "1.3B": 6.5,   # 6.5GB VRAM per worker</text>
  <text x="120" y="442" class="code-text">    "3.3B": 12.0   # 12GB VRAM per worker</text>
  <text x="120" y="455" class="code-text">}</text>
  <text x="120" y="468" class="code-text">memory_per_worker = model_memory_requirements[model_size]</text>

  <!-- Dynamic Worker Calculation -->
  <rect x="650" y="340" width="500" height="150" class="gpu-box" rx="8"/>
  <text x="900" y="365" class="section-title white-text">Dynamic Worker Calculation</text>
  <rect x="660" y="375" width="480" height="105" class="code-box" rx="4"/>
  <text x="670" y="390" class="code-text"># 80% VRAM utilization (safety margin)</text>
  <text x="670" y="403" class="code-text">max_workers = int((gpu_memory_gb * 0.8)</text>
  <text x="670" y="416" class="code-text">              / memory_per_worker)</text>
  <text x="670" y="429" class="code-text"># Conservative limits: 1-3 workers per GPU</text>
  <text x="670" y="442" class="code-text">max_workers = max(1, min(max_workers, 3))</text>
  <text x="670" y="455" class="code-text"># Example: 24GB GPU / 6.5GB = 2 workers</text>
  <text x="670" y="468" class="code-text">#          32GB GPU / 6.5GB = 3 workers</text>

  <!-- Load Distribution Phase -->
  <text x="700" y="540" class="subtitle">Phase 3: Multi-GPU Load Distribution</text>

  <!-- Single GPU -->
  <rect x="50" y="570" width="250" height="120" class="gpu-box" rx="8"/>
  <text x="175" y="595" class="section-title white-text">Single GPU (1x)</text>
  <text x="175" y="615" class="small-label white-text">Multi-worker on same GPU</text>
  <text x="175" y="635" class="small-label white-text">GPU Workers: 1-3</text>
  <text x="175" y="650" class="small-label white-text">Batch Size: 8</text>
  <text x="175" y="665" class="small-label white-text">CPU Workers: 12</text>
  <text x="175" y="680" class="small-label white-text">Throughput: 1x baseline</text>

  <!-- Dual GPU -->
  <rect x="350" y="570" width="250" height="120" class="gpu-box" rx="8"/>
  <text x="475" y="595" class="section-title white-text">Dual GPU (2x)</text>
  <text x="475" y="615" class="small-label white-text">Balanced load distribution</text>
  <text x="475" y="635" class="small-label white-text">GPU Workers: 2</text>
  <text x="475" y="650" class="small-label white-text">Batch Size: 12</text>
  <text x="475" y="665" class="small-label white-text">CPU Workers: 16</text>
  <text x="475" y="680" class="small-label white-text">Throughput: 4x baseline</text>

  <!-- Triple GPU -->
  <rect x="650" y="570" width="250" height="120" class="gpu-box" rx="8"/>
  <text x="775" y="595" class="section-title white-text">Triple GPU (3x)</text>
  <text x="775" y="615" class="small-label white-text">Maximum parallelization</text>
  <text x="775" y="635" class="small-label white-text">GPU Workers: 3</text>
  <text x="775" y="650" class="small-label white-text">Batch Size: 16</text>
  <text x="775" y="665" class="small-label white-text">CPU Workers: 20</text>
  <text x="775" y="680" class="small-label white-text">Throughput: 7x baseline</text>

  <!-- CPU Fallback -->
  <rect x="950" y="570" width="250" height="120" class="cpu-box" rx="8"/>
  <text x="1075" y="595" class="section-title white-text">CPU Fallback</text>
  <text x="1075" y="615" class="small-label white-text">No GPU available/OOM</text>
  <text x="1075" y="635" class="small-label white-text">GPU Workers: 0</text>
  <text x="1075" y="650" class="small-label white-text">Batch Size: 4</text>
  <text x="1075" y="665" class="small-label white-text">CPU Workers: 8-16</text>
  <text x="1075" y="680" class="small-label white-text">Throughput: 0.3x baseline</text>

  <!-- Dynamic Worker Redeployment -->
  <text x="700" y="740" class="subtitle">Phase 4: Real-Time Worker Redeployment</text>

  <rect x="100" y="770" width="550" height="140" class="innovation-box" rx="8"/>
  <text x="375" y="795" class="section-title white-text">Intelligent Worker Redeployment Algorithm</text>
  <rect x="110" y="805" width="530" height="95" class="code-box" rx="4"/>
  <text x="120" y="820" class="code-text"># Patent Claim: Real-time worker reallocation</text>
  <text x="120" y="833" class="code-text">if self.worker_allocation.idle_workers > 0:</text>
  <text x="120" y="846" class="code-text">    resources = self.monitor_system_resources()</text>
  <text x="120" y="859" class="code-text">    if resources['cpu_percent'] < 85 and</text>
  <text x="120" y="872" class="code-text">       resources['memory_percent'] < 90:</text>
  <text x="120" y="885" class="code-text">        workers_to_redeploy = idle_workers // 2</text>
  <text x="120" y="898" class="code-text">        # Idle preprocessing → Active translation</text>

  <!-- Worker States -->
  <rect x="700" y="770" width="250" height="140" class="worker-box" rx="8"/>
  <text x="825" y="795" class="section-title white-text">Worker States</text>
  <rect x="710" y="810" width="100" height="30" class="cpu-box" rx="4"/>
  <text x="760" y="830" class="small-label white-text">Preprocessing</text>
  <rect x="820" y="810" width="100" height="30" class="gpu-box" rx="4"/>
  <text x="870" y="830" class="small-label white-text">Translation</text>
  <rect x="710" y="850" width="100" height="30" class="success-box" rx="4"/>
  <text x="760" y="870" class="small-label white-text">Postprocessing</text>
  <rect x="820" y="850" width="100" height="30" class="code-box" rx="4"/>
  <text x="870" y="870" class="label">Idle</text>

  <!-- Resource Monitoring -->
  <rect x="1000" y="770" width="350" height="140" class="success-box" rx="8"/>
  <text x="1175" y="795" class="section-title white-text">System Resource Monitoring</text>
  <text x="1020" y="820" class="small-label white-text">✓ CPU utilization (target: < 85%)</text>
  <text x="1020" y="838" class="small-label white-text">✓ Memory utilization (target: < 90%)</text>
  <text x="1020" y="856" class="small-label white-text">✓ GPU memory (target: 80% max)</text>
  <text x="1020" y="874" class="small-label white-text">✓ Disk I/O bandwidth</text>
  <text x="1020" y="892" class="small-label white-text">✓ Network latency (API calls)</text>
  <text x="1020" y="905" class="small-label white-text">Real-time adjustment every 30 seconds</text>

  <!-- Fallback Mechanism -->
  <text x="700" y="960" class="subtitle">Phase 5: Intelligent Fallback System</text>

  <rect x="200" y="990" width="380" height="90" class="gpu-box" rx="8"/>
  <text x="390" y="1015" class="section-title white-text">GPU Processing (Primary)</text>
  <rect x="210" y="1025" width="360" height="45" class="code-box" rx="4"/>
  <text x="220" y="1040" class="code-text">try:</text>
  <text x="220" y="1053" class="code-text">    return self._process_with_gpu(terms_batch)</text>
  <text x="220" y="1066" class="code-text">except RuntimeError as e:  # CUDA OOM</text>

  <rect x="620" y="990" width="380" height="90" class="innovation-box" rx="8"/>
  <text x="810" y="1015" class="section-title white-text">Error Handling (Detection)</text>
  <rect x="630" y="1025" width="360" height="45" class="code-box" rx="4"/>
  <text x="640" y="1040" class="code-text">if "CUDA out of memory" in str(e):</text>
  <text x="640" y="1053" class="code-text">    logger.warning("GPU OOM, fallback to CPU")</text>
  <text x="640" y="1066" class="code-text">    torch.cuda.empty_cache()</text>

  <rect x="1040" y="990" width="280" height="90" class="cpu-box" rx="8"/>
  <text x="1180" y="1015" class="section-title white-text">CPU Fallback (Secondary)</text>
  <rect x="1050" y="1025" width="260" height="45" class="code-box" rx="4"/>
  <text x="1060" y="1040" class="code-text">return self._process_with_cpu(</text>
  <text x="1060" y="1053" class="code-text">    terms_batch)</text>
  <text x="1060" y="1066" class="code-text"># Zero data loss!</text>

  <!-- Arrows showing flow -->
  <line x1="250" y1="260" x2="350" y2="340" class="arrow"/>
  <line x1="700" y1="260" x2="900" y2="340" class="arrow"/>
  <line x1="1150" y1="260" x2="900" y2="340" class="arrow"/>

  <line x1="350" y1="490" x2="175" y2="570" class="gpu-arrow"/>
  <line x1="900" y1="490" x2="475" y2="570" class="gpu-arrow"/>
  <line x1="900" y1="490" x2="775" y2="570" class="gpu-arrow"/>
  <line x1="900" y1="490" x2="1075" y2="570" class="cpu-arrow"/>

  <line x1="390" y1="1080" x2="810" y2="1025" class="arrow"/>
  <line x1="810" y1="1080" x2="1180" y2="1080" class="arrow"/>

  <!-- Key Features Box -->
  <rect x="50" y="20" width="350" height="60" class="success-box" rx="8"/>
  <text x="225" y="45" class="small-label white-text">✓ Dynamic VRAM calculation</text>
  <text x="225" y="60" class="small-label white-text">✓ OS-specific optimization</text>
  <text x="225" y="75" class="small-label white-text">✓ Multi-GPU load balancing</text>

  <rect x="1000" y="20" width="350" height="60" class="success-box" rx="8"/>
  <text x="1175" y="45" class="small-label white-text">✓ Real-time worker redeployment</text>
  <text x="1175" y="60" class="small-label white-text">✓ Graceful fallback (GPU→CPU)</text>
  <text x="1175" y="75" class="small-label white-text">✓ Zero data loss on failures</text>

  <!-- Footer -->
  <rect x="0" y="0" width="1400" height="1100" fill="none" stroke="#2c3e50" stroke-width="2"/>
  
</svg>

